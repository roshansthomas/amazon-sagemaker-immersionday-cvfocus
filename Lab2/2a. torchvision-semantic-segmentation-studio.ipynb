{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139bfed8",
   "metadata": {},
   "source": [
    "# Train and deploy a Semantic Segmentation model using pytorch\n",
    "\n",
    "In this lab, you will learn how to train a semantic segmentation model with a model using the [torchvision subpackage](https://pytorch.org/vision/stable/models.html#semantic-segmentation). We will be using the [DeepLabV3 ResNet50 model](https://arxiv.org/abs/1706.05587) and training it on the [SpaceNet dataset](https://spacenet.ai/spacenet-buildings-dataset-v2/).\n",
    "\n",
    "We will be exploring concepts on how to implement a custom model with the PyTorch framework using script mode.\n",
    "\n",
    "Reference:\n",
    "- Use PyTorch with the SageMaker Python SDK - https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb816ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os, time, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/LAB-pytorch-semantic-segmentation'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704ff0a",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "We will be downloading the spacenet dataset and uncompressing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ff1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://spacenet-dataset/spacenet/SN2_buildings/tarballs/SN2_buildings_train_AOI_3_Paris.tar.gz ./dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65453aca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf ./dataset/SN2_buildings_train_AOI_3_Paris.tar.gz -C ./dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef2af9",
   "metadata": {},
   "source": [
    "### Set Plotting preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e8d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3cf86c",
   "metadata": {},
   "source": [
    "## Review data\n",
    "\n",
    "Let's review the dataset we've just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb4680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = './dataset/AOI_3_Paris_Train/'\n",
    "img_dir = os.path.join(data_dir, 'RGB-PanSharpen')\n",
    "bldg_dir = os.path.join(data_dir, 'geojson', 'buildings')\n",
    "\n",
    "# Prefix of all filename - naming convention\n",
    "midfix = 'AOI_3_Paris_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd455cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_bands(img, lower_pct = 1, upper_pct = 99):\n",
    "    \"\"\"\n",
    "    Rescale the bands of a multichannel image for display\n",
    "    \"\"\"\n",
    "    # Loop through the image bands, rescaling each one\n",
    "    img_scaled = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    for i in range(img.shape[2]):\n",
    "        \n",
    "        band = img[:, :, i]\n",
    "        \n",
    "        # Pick out the lower and upper percentiles\n",
    "        lower, upper = np.percentile(band, [lower_pct, upper_pct])\n",
    "        \n",
    "        # Normalize the band\n",
    "        band = (band - lower) / (upper - lower) * 255\n",
    "        \n",
    "        # Clip the high and low values, and cast to uint8\n",
    "        img_scaled[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "        \n",
    "    return img_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231093b",
   "metadata": {},
   "source": [
    "#### What's happening here?\n",
    "The following cell is loading a sample image and mask from the SpaceNet dataset. We are leveraging the `sol.vector.mask.footprint_mask()` function to convert the geojson file into an array format. We are then using the plotting library to preview our image and mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0b532",
   "metadata": {},
   "source": [
    "In the image above, you can see the original satellite image and the building mask generated from the accompanying geojson file. We used the solaris library to conver the geojson into an image so that we can visualise it.\n",
    "\n",
    "**Note** For the satellite image, we created a function `scale_bands()` to process the image as the original image from dataset is an 11-bit image stored in 16 bit integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784190f",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "\n",
    "Now that we have some clarity on our dataset, let's process the rest of the images and masks using the `scale_bands()` for the images and `sol.vector.mask.footprint_mask()` function for the mask. We will also split out dataset into training and test and upload it to a designated S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1283d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir) \n",
    "    \n",
    "training_dir = os.path.join(data_dir, 'train/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "\n",
    "if not os.path.exists(training_dir):\n",
    "    os.mkdir(training_dir) \n",
    "    \n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir) \n",
    "\n",
    "training_img_dir = os.path.join(training_dir, 'img/')\n",
    "\n",
    "if not os.path.exists(training_img_dir):\n",
    "    os.mkdir(training_img_dir)\n",
    "    \n",
    "training_mask_dir = os.path.join(training_dir, 'mask/')\n",
    "\n",
    "if not os.path.exists(training_mask_dir):\n",
    "    os.mkdir(training_mask_dir) \n",
    "    \n",
    "    \n",
    "test_img_dir = os.path.join(test_dir, 'img/')\n",
    "\n",
    "if not os.path.exists(test_img_dir):\n",
    "    os.mkdir(test_img_dir)\n",
    "    \n",
    "test_mask_dir = os.path.join(test_dir, 'mask/')\n",
    "\n",
    "if not os.path.exists(test_mask_dir):\n",
    "    os.mkdir(test_mask_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981b836",
   "metadata": {},
   "source": [
    "### Split dataset\n",
    "\n",
    "In the next few cells, we will split out dataset into training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81f3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get list of images\n",
    "ListImages=os.listdir(img_dir)\n",
    "\n",
    "# Split dataset\n",
    "train = ListImages[0:int(0.7 * len(ListImages))]\n",
    "test = ListImages[int(0.7 * len(ListImages)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d709eb",
   "metadata": {},
   "source": [
    "### Process dataset\n",
    "\n",
    "Here we will process our images and masks and save it as a tif file.\n",
    "\n",
    "We achieve this by reading in the groundtruth data, generate a mask of the buildings and saving it as a tif file.\n",
    "\n",
    "**Note:** Typically this will be done using a [Amazon SageMaker Processing job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html) so that you can process thousands of images at scale and within a pipeline. But for simplicity, we will be doing the image processing for a few hundred of images within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98cc275-9f04-45a9-8aec-a33391f50647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_polygon_list(wkt_list_pandas, imageId):\n",
    "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
    "    poly_def = df_image.PolygonWKT_Pix\n",
    "    polygonList = None\n",
    "    polygonList = [wkt_loads(x) for x in poly_def]\n",
    "    return polygonList, poly_def\n",
    "\n",
    "\n",
    "def _get_and_convert_contours(polygonList, raster_img_size, poly_def):\n",
    "    perim_list = []\n",
    "    interior_list = []\n",
    "    if len(poly_def) < 2:\n",
    "        return None\n",
    "    for k in range(len(poly_def)):\n",
    "        poly = polygonList[k]\n",
    "        perim = np.array(list(poly.exterior.coords))\n",
    "        perim_c = np.array(perim[:,:-1]).astype(int)\n",
    "        perim_list.append(perim_c)\n",
    "        for pi in poly.interiors:\n",
    "            interior = np.array(list(pi.coords))\n",
    "#            interior_c = _convert_coordinates_to_raster(interior, raster_img_size)\n",
    "            interior_list.append(np.int32(interior[:,:-1]))\n",
    "    return perim_list,interior_list\n",
    "\n",
    "\n",
    "def _plot_mask_from_contours(raster_img_size, ext_pts, int_pts, class_value = 1):\n",
    "    img_mask = np.zeros(raster_img_size,np.uint8)\n",
    "    cv2.fillPoly(img_mask, np.asarray(ext_pts),1)\n",
    "    cv2.fillPoly(img_mask, np.asarray(int_pts),0)\n",
    "    return img_mask\n",
    "\n",
    "def generate_mask_for_image_and_class(raster_size, imageId, wkt_list_pandas):\n",
    "    polygon_list, poly_def = _get_polygon_list(wkt_list_pandas,imageId)\n",
    "    if len(polygon_list) < 2:\n",
    "        # print(\"Mask zero\")\n",
    "        mask = np.zeros(raster_size,np.uint8)\n",
    "        return mask, False\n",
    "    else:\n",
    "        print(\"Mask non-zero\")\n",
    "        ext, inte = _get_and_convert_contours(polygon_list,raster_size, poly_def)\n",
    "        mask = _plot_mask_from_contours(raster_size,ext, inte,1)\n",
    "        return mask, True\n",
    "    \n",
    "def get_image_id(image_file_name):\n",
    "    return image_file_name[15:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75265ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get groundtruth data\n",
    "groundtruth_df = pd.read_csv('./dataset/AOI_3_Paris_Train/summaryData/AOI_3_Paris_Train_Building_Solutions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05923771-fcf6-4d45-9186-c1d63947543a",
   "metadata": {},
   "source": [
    "Visualise a sample of the mask from the groundtruth coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d71802-0097-40e3-8ca0-457c14383730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display example masks generated from ground truth polygons\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(121)\n",
    "example_mask, _is_mask = generate_mask_for_image_and_class((650,650), 'AOI_3_Paris_img100', groundtruth_df)\n",
    "plt.imshow(example_mask)\n",
    "plt.subplot(122)\n",
    "example_mask, _is_mask = generate_mask_for_image_and_class((650,650), 'AOI_3_Paris_img211', groundtruth_df)\n",
    "plt.imshow(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e4464-c38c-4928-aec3-58fd71fb56c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process images, mask and save it as a tif file which will use for training\n",
    "def process_images_and_mask(image_list, image_dir, geojson_dir, output_dir, ground_truth):\n",
    "    for img_file in image_list:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        img = skimage.io.imread(img_path)\n",
    "        \n",
    "        # Convert image from 11-bit to 8-bit\n",
    "        img = scale_bands(img)\n",
    "        \n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        \n",
    "        prefix = 'RGB-PanSharpen_' + midfix\n",
    "        if img_file.startswith(prefix):\n",
    "            file_suffix = os.path.splitext(img_file[len(prefix):])[0]\n",
    "            \n",
    "            if os.path.exists(os.path.join(geojson_dir, bldg_file)):\n",
    "                # Create training mask\n",
    "                img_mask, is_mask = generate_mask_for_image_and_class((height,width), get_image_id(img_file), ground_truth)\n",
    "\n",
    "                # Only save image if there is a mask\n",
    "                if is_mask:\n",
    "                    output_image_filename = file_suffix + '.tif'\n",
    "\n",
    "                    # Save mask\n",
    "                    skimage.io.imsave(os.path.join(output_dir,'mask', output_image_filename), img_mask, check_contrast=False)\n",
    "\n",
    "                    # Save image\n",
    "                    skimage.io.imsave(os.path.join(output_dir,'img', output_image_filename), img, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f77d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process our training dataset\n",
    "process_images_and_mask(train, img_dir, bldg_dir, training_dir, groundtruth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab7cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process our test dataset\n",
    "process_images_and_mask(test, img_dir, bldg_dir, test_dir, groundtruth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128949d",
   "metadata": {},
   "source": [
    "### Upload dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4ddaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136dc2c3",
   "metadata": {},
   "source": [
    "## Setup SageMaker Experiments\n",
    "\n",
    "With [Amazon SageMaker Experiments](https://aws.amazon.com/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings/), we can track multiple iterations of our training job. With Amazon SageMaker Experiments, you can track the hyperparameters, datasets and algorithms used for each trial and easily compare them. \n",
    "\n",
    "In this section we will setup create an experiment and in the later section create a trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce27bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import strftime\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cae3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "seg_experiment = Experiment.create(\n",
    "    experiment_name=\"spacenet-semantic-segmentation-{}\".format(create_date), \n",
    "    description=\"Semantic Segmentation for the spacenet aerial images\",\n",
    "    tags = [{'Key': 'Environment', 'Value': 'demo1'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f79402",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In this lab, we will be training a model using the [bring your own model with script mode](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-script-mode/sagemaker-script-mode.html). To achieve this, we will be using the [PyTorch with SageMaker python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html).\n",
    "\n",
    "By using the PyTorch sdk, we will be using a pre-build PyTorch container as our base platform to run our training script. We will provide the container with a custom training script, `script/train.py`. Our custom training script includes a dataloader to load our training and test dataset, our model definition which loads the DeepLabV3 ResNet50 from the torchvision library and supporting function to initialise the neural net and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch, PyTorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36265e",
   "metadata": {},
   "source": [
    "### Test training script in local mode\n",
    "\n",
    "To facilitate debugging your training script, you can train your model using local mode. This can be achieved by setting the `instance_type` variable to `local`. The following code will execute a training job for one epoch.\n",
    "\n",
    "The following code exmample below shows you how to do this. This is done by launching a local training job (`instance_type='local'`) with a pytorch framework version of 2.0.0 (`framework_version='1.8.0'`). The training job will load our training script **train.py** (`entry_point=train.py`) from our source directory **script** (`source_dir=script`). Within the `hyperparameters` variable, we set the training job to run for 1 epoch, a batch size of 16 and a learning rate of 0.0005.\n",
    "\n",
    "```\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=\"script\",\n",
    "                    role=role,\n",
    "                    py_version='py310',\n",
    "                    framework_version='2.0.0',\n",
    "                    instance_count=1,\n",
    "                    instance_type='local',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 1,\n",
    "                        'batch-size': 16,\n",
    "                        'lr': 0.0005,\n",
    "                        'log-interval': 10\n",
    "                    })\n",
    "```                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44f001",
   "metadata": {},
   "source": [
    "### Execute a SageMaker Job\n",
    "\n",
    "Once you're satisfied with your training script, the next process is to scale your model training by leveraging an Amazon SageMaker training job. To do so we will set the `instance_type` to a specific [Amazon SageMaker Instance types](https://aws.amazon.com/sagemaker/pricing/). In this example, we will be using a `ml.g4dn.2xlarge` instance that has a gpu.\n",
    "\n",
    "When the `fit()` function is called, an Amazon SageMaker training job will be initialised. If you have access to the console, you will be able visualise your training job execution [https://ap-southeast-2.console.aws.amazon.com/sagemaker/home?region=ap-southeast-2#/jobs](https://ap-southeast-2.console.aws.amazon.com/sagemaker/home?region=ap-southeast-2#/jobs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_trial = Trial.create(trial_name = \"spacenet-semantic-segmentation-{}-{}\".format(create_date, int(time.time())),\n",
    "                          experiment_name = seg_experiment.experiment_name,\n",
    "                          tags = [{'Key': 'Environment', 'Value': 'demo1'}])\n",
    "\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir=\"script\",\n",
    "                    role=role,\n",
    "                    py_version='py310',\n",
    "                    framework_version='2.0.0',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.g4dn.4xlarge',\n",
    "                    volume_size=50,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10,\n",
    "                        'lr': 1E-3,\n",
    "                        'batch-size': 16,\n",
    "                        'log-interval': 10\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'training': inputs}, experiment_config = {\n",
    "        # \"ExperimentName\"\n",
    "        \"TrialName\" : seg_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\" : \"TrainingJob\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9c685",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4ceab",
   "metadata": {},
   "source": [
    "## Create a real-time endpoint\n",
    "As we are using a custom model and will be sending images as an input, we will need to override the default mechanism of how Amazon SageMaker inference container loads our model, process the input request and output response. This is achieved by overriding the following respective functions implemented in the `script/inference.py` file:\n",
    "\n",
    "- model_fn: Override the model loading function to load the deeplabv3_resnet50 model with weights from our training job.\n",
    "- input_fn: Override the input function convert the incoming image payload into a tensor suitable for prediction/\n",
    "- output_fn: Override the output function to convert the output prediction into a numpy array.\n",
    "\n",
    "More information on how to override the inference functions here:\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html\n",
    "\n",
    "#### What is happening here?\n",
    "We are using the `PyTorchModel()` class to define our real-time inference configuration. The trained model is parse through the `model_data` parameter and the source of the inference script is specified through the `source_dir` for the directory and `entry_point` for the script.\n",
    "\n",
    "The real-time inference endpoint is then deployed using the `deploy()` function where we specify the initial number of instances (`initial_instance_count`) and desired  instance type (`instance_type`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_serving_model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    role=role,\n",
    "    framework_version='1.8.0',\n",
    "    py_version='py3',\n",
    "    entry_point='inference.py',\n",
    "    source_dir=\"script\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_predictor = pytorch_serving_model.deploy(initial_instance_count=1,\n",
    "        instance_type='ml.m4.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6104ba",
   "metadata": {},
   "source": [
    "### Run some predictions\n",
    "\n",
    "Now that our real-time endpoint is up, let us run some predictions. For this lab, as we only train a model is a few epoch, we won't be expecting an accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a test image\n",
    "# img_path = './data/test/img/img100.tif'\n",
    "# mask_path = './data/test/mask/img100.tif'\n",
    "\n",
    "# Using a train image\n",
    "img_path = './data/train/img/img1011.tif'\n",
    "mask_path = './data/train/mask/img1011.tif'\n",
    "\n",
    "with open(img_path, \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=hosted_predictor.endpoint_name, ContentType=\"application/x-image\", Body=payload\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the output response\n",
    "result = json.loads(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_path, \"rb\") as image_file, open(mask_path, \"rb\") as mask_file:\n",
    "    image = Image.open(image_file).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Satellite image')\n",
    "    ax[1].imshow(np.array(result) > 0.1, cmap='Blues')\n",
    "    ax[1].set_title('Building masks prediction')\n",
    "    ax[2].imshow(mask, cmap='Blues')\n",
    "    ax[2].set_title('Building ground truth')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df848a",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "As the real-time inference endpoint is running 24/7, it is often best practice to always delete the endpoint once we are done with testing. The `delete_endpoint()` function will delete our running endpoint and its associated configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.geospatial.interactive",
  "kernelspec": {
   "display_name": "Python 3 (Geospatial 1.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:081189585635:image/sagemaker-geospatial-v1-0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
